{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"},{"sourceId":7924525,"sourceType":"datasetVersion","datasetId":4657249},{"sourceId":168465212,"sourceType":"kernelVersion"},{"sourceId":168466214,"sourceType":"kernelVersion"}],"dockerImageVersionId":30646,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pwd","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport zipfile\n\ndef zip_folder(folder_path, output_zip):\n    \"\"\"\n    Zip the contents of an entire folder (with that folder included\n    in the archive). Empty directories are included in the archive as well.\n    \"\"\"\n    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        lenDirPath = len(folder_path)\n        for root, _, files in os.walk(folder_path):\n            # Include all subdirectories, including empty ones.\n            for dirName in os.listdir(root):\n                dirPath = os.path.join(root, dirName)\n                if os.path.isdir(dirPath):\n                    zipf.write(dirPath, os.path.relpath(dirPath, folder_path))\n            # Add files\n            for file in files:\n                filePath = os.path.join(root, file)\n                zipf.write(filePath, os.path.relpath(filePath, folder_path))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zip_folder(\"/kaggle/input/isig-wheels/iisignature-0.24\", \"./isig.zip\")\n\n!pip install \"./isig.zip\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from basic_preprocessing_utility_script import process_as_h5, signature, get_eeg_sp_data, zip_folder","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/usr/lib')\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport time\nimport h5py\n\nimport iisignature as isig\n\nimport matplotlib.pyplot as plt\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-20T16:57:53.295513Z","iopub.execute_input":"2024-03-20T16:57:53.295895Z","iopub.status.idle":"2024-03-20T16:57:53.670753Z","shell.execute_reply.started":"2024-03-20T16:57:53.295862Z","shell.execute_reply":"2024-03-20T16:57:53.669003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# filename = '/kaggle/input/hms-harmful-brain-activity-classification/train.csv'\n# process_as_h5(filename, num_examples = 1000)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:57:53.673609Z","iopub.execute_input":"2024-03-20T16:57:53.673983Z","iopub.status.idle":"2024-03-20T16:57:53.678911Z","shell.execute_reply.started":"2024-03-20T16:57:53.67393Z","shell.execute_reply":"2024-03-20T16:57:53.677617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hdf5_file = '/kaggle/input/generate-h5-data/hdf5/processed_dataset_1000.h5'\nnum_examples = 1000\n\n\n\nwith h5py.File(hdf5_file, 'r') as file:\n    # List all groups\n    \n    print(\"Keys: %s\" % file.keys())\n    \n    file_keys = list(file.keys())\n\n    a_group_key = list(file.keys())[0]\n    \n    eeg_data = np.array(file[f\"eeg\"])\n    sp_data = np.array(file[f\"sp\"])\n    targets = np.array(file[f\"targets\"])\n    num_votes = np.array(file[f\"num_votes\"])\n    num_votes = num_votes.reshape((len(num_votes), -1))\n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:57:53.680154Z","iopub.execute_input":"2024-03-20T16:57:53.680493Z","iopub.status.idle":"2024-03-20T16:57:57.194541Z","shell.execute_reply.started":"2024-03-20T16:57:53.680456Z","shell.execute_reply":"2024-03-20T16:57:57.193131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## We try just using the EEG data","metadata":{}},{"cell_type":"code","source":"print(eeg_data.shape)\nprint(targets.shape)\nprint(sp_data.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:57:57.196102Z","iopub.execute_input":"2024-03-20T16:57:57.196446Z","iopub.status.idle":"2024-03-20T16:57:57.202113Z","shell.execute_reply.started":"2024-03-20T16:57:57.196417Z","shell.execute_reply":"2024-03-20T16:57:57.201032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## We try applying the signature across each signal","metadata":{}},{"cell_type":"markdown","source":"### We apply the signature across the different streams (there are 4 of length 4, and then one 'other' of length 2)","metadata":{}},{"cell_type":"code","source":"eeg_streams = [eeg_data[:,:,:4],  eeg_data[:,:,4:8], eeg_data[:,:,8:12], eeg_data[:,:,12:16], eeg_data[:,:,16:]]\neeg_stream_sig = [signature(stream, level=4) for stream in eeg_streams]\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:57:57.203558Z","iopub.execute_input":"2024-03-20T16:57:57.204533Z","iopub.status.idle":"2024-03-20T16:58:12.929348Z","shell.execute_reply.started":"2024-03-20T16:57:57.204497Z","shell.execute_reply":"2024-03-20T16:58:12.928216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for stream in eeg_stream_sig:\n    print(stream.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:12.930697Z","iopub.execute_input":"2024-03-20T16:58:12.93114Z","iopub.status.idle":"2024-03-20T16:58:12.937719Z","shell.execute_reply.started":"2024-03-20T16:58:12.931108Z","shell.execute_reply":"2024-03-20T16:58:12.936438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eeg_sig = np.concatenate(eeg_stream_sig, axis=-1)\n\nprint(eeg_sig.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:12.939456Z","iopub.execute_input":"2024-03-20T16:58:12.940007Z","iopub.status.idle":"2024-03-20T16:58:12.969816Z","shell.execute_reply.started":"2024-03-20T16:58:12.939975Z","shell.execute_reply":"2024-03-20T16:58:12.968485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create historgram of values in eeg_sig to see in what range values in the signautre are in","metadata":{}},{"cell_type":"code","source":"# Creating the histogram\nimport matplotlib.pyplot as plt\n\nplt.hist(eeg_sig.reshape(-1), bins=100, alpha=0.7, color='green', edgecolor='black')\n\nplt.title('Histogram of Values in Array')\nplt.xlabel('Value')\nplt.ylabel('Frequency')\n\n# Display the histogram\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:12.976417Z","iopub.execute_input":"2024-03-20T16:58:12.97683Z","iopub.status.idle":"2024-03-20T16:58:13.586311Z","shell.execute_reply.started":"2024-03-20T16:58:12.976797Z","shell.execute_reply":"2024-03-20T16:58:13.584959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the histogram\nplt.hist(eeg_sig[0], bins=30, alpha=0.7, color='green', edgecolor='black')\n\nplt.title('Histogram of Values in Array')\nplt.xlabel('Value')\nplt.ylabel('Frequency')\n\n# Display the histogram\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:13.588116Z","iopub.execute_input":"2024-03-20T16:58:13.588612Z","iopub.status.idle":"2024-03-20T16:58:13.887623Z","shell.execute_reply.started":"2024-03-20T16:58:13.588569Z","shell.execute_reply":"2024-03-20T16:58:13.886024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We clip the output of the signature to be between -0.5 and 0.5","metadata":{}},{"cell_type":"code","source":"eeg_sig_clip = np.clip(eeg_sig, a_min=-0.5, a_max=0.5)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:13.889518Z","iopub.execute_input":"2024-03-20T16:58:13.890035Z","iopub.status.idle":"2024-03-20T16:58:13.901362Z","shell.execute_reply.started":"2024-03-20T16:58:13.889992Z","shell.execute_reply":"2024-03-20T16:58:13.900033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Write the above preprocessing steps as a single function","metadata":{}},{"cell_type":"code","source":"def preprocess(pre_eeg):\n    pre_eeg_streams = [pre_eeg[:,:,:4],  pre_eeg[:,:,4:8], pre_eeg[:,:,8:12],\n                       pre_eeg[:,:,12:16], pre_eeg[:,:,16:]]\n    \n    pre_eeg_stream_sig = [signature(stream, level=4) for stream in pre_eeg_streams]\n    pre_eeg_sig = np.concatenate(pre_eeg_stream_sig, axis=-1)\n    pre_eeg_sig_clip = np.clip(pre_eeg_sig, a_min=-0.5, a_max=0.5)\n    return pre_eeg_sig_clip\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:13.902875Z","iopub.execute_input":"2024-03-20T16:58:13.903484Z","iopub.status.idle":"2024-03-20T16:58:13.912816Z","shell.execute_reply.started":"2024-03-20T16:58:13.903452Z","shell.execute_reply":"2024-03-20T16:58:13.911205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader, random_split\n\n# Mock data\nfeatures = eeg_sig_clip\ntargets = targets\n\n# Convert to PyTorch tensors\nfeatures_tensor = torch.tensor(features, dtype=torch.float32)\ntargets_tensor = torch.tensor(targets, dtype=torch.float32)\n\n# Create a TensorDataset\ndataset = TensorDataset(features_tensor, targets_tensor)\n\n# Split dataset into train and test sets\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n\n\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass DeeperNN(nn.Module):\n    def __init__(self):\n        super(DeeperNN, self).__init__()\n        self.fc1 = nn.Linear(1390, 1024)  # Increase the number of neurons\n        self.bn1 = nn.BatchNorm1d(1024)   # Batch normalization\n        self.dropout1 = nn.Dropout(0.5)   # Dropout\n        \n        self.fc2 = nn.Linear(1024, 512)\n        self.bn2 = nn.BatchNorm1d(512)\n        self.dropout2 = nn.Dropout(0.5)\n        \n        self.fc3 = nn.Linear(512, 256)\n        self.bn3 = nn.BatchNorm1d(256)\n        self.dropout3 = nn.Dropout(0.5)\n        \n        self.fc4 = nn.Linear(256, 128)\n        self.bn4 = nn.BatchNorm1d(128)\n        self.dropout4 = nn.Dropout(0.5)\n        \n        self.fc5 = nn.Linear(128, 6)     # Final layer remains the same\n\n    def forward(self, x):\n        x = F.relu(self.bn1(self.fc1(x)))\n        x = self.dropout1(x)\n        \n        x = F.relu(self.bn2(self.fc2(x)))\n        x = self.dropout2(x)\n        \n        x = F.relu(self.bn3(self.fc3(x)))\n        x = self.dropout3(x)\n        \n        x = F.relu(self.bn4(self.fc4(x)))\n        x = self.dropout4(x)\n        \n        x = self.fc5(x)\n        return F.log_softmax(x, dim=1) # Ensure output sums to 1\n\n# Initialize the model\nmodel = DeeperNN()\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:13.914351Z","iopub.execute_input":"2024-03-20T16:58:13.915245Z","iopub.status.idle":"2024-03-20T16:58:17.198812Z","shell.execute_reply.started":"2024-03-20T16:58:13.915212Z","shell.execute_reply":"2024-03-20T16:58:17.197477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\nimport matplotlib.pyplot as plt\n\n# Assume nn, model, train_loader, and test_loader are already defined\n\n# Loss function and optimizer\ncriterion = nn.KLDivLoss(reduction='batchmean')\noptimizer = optim.Adam(model.parameters(), lr=0.01)\n\nlosses = []  # List to store the average loss per epoch\ntest_losses = []  # List to store the average test loss per epoch\n\n# Training loop\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    model.train()  # Set the model to training mode\n    total_loss = 0\n    for inputs, labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n    losses.append(avg_loss)\n\n    # Evaluate on test set\n    model.eval()  # Set the model to evaluation mode\n    total_test_loss = 0\n    with torch.no_grad():  # Disable gradient calculation for evaluation\n        for inputs, labels in test_loader:\n            outputs = model(inputs)\n            test_loss = criterion(outputs, labels)\n            total_test_loss += test_loss.item()\n    \n    avg_test_loss = total_test_loss / len(test_loader)\n    test_losses.append(avg_test_loss)\n    \n    print(f\"Epoch {epoch+1}, Training Loss: {avg_loss}, Test Loss: {avg_test_loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:17.201288Z","iopub.execute_input":"2024-03-20T16:58:17.20213Z","iopub.status.idle":"2024-03-20T16:58:45.294972Z","shell.execute_reply.started":"2024-03-20T16:58:17.202079Z","shell.execute_reply":"2024-03-20T16:58:45.293586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Plotting\nplt.plot(losses, label='Training Loss')\nplt.plot(test_losses, label='Test Loss')\nplt.title('Training vs Test Loss')\nplt.xlabel('Epoch')\nplt.ylabel('KL Divergence Loss')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:45.296625Z","iopub.execute_input":"2024-03-20T16:58:45.297213Z","iopub.status.idle":"2024-03-20T16:58:45.565131Z","shell.execute_reply.started":"2024-03-20T16:58:45.29718Z","shell.execute_reply":"2024-03-20T16:58:45.563971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Try Submitting","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\nprint('Test shape:',test.shape)\n\n\nEEG_SUB_PATH_TEMPL = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/'\nSP_SUB_PATH_TEMPL = '/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/'\n\ntest.head()\n\ntest.iloc[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:45.567108Z","iopub.execute_input":"2024-03-20T16:58:45.567911Z","iopub.status.idle":"2024-03-20T16:58:45.594114Z","shell.execute_reply.started":"2024-03-20T16:58:45.56787Z","shell.execute_reply":"2024-03-20T16:58:45.592884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read all spectrograms\nPATH = '/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms'\nfiles = os.listdir(PATH)\nprint(f'There are {len(files)} test spectrogram parquets')\ntest_specs = {}\nfor i,f in enumerate(files):\n    tmp = pd.read_parquet(f'{PATH}/{f}')\n    name = int(f.split('.')[0])\n    print(tmp)\n    test_specs[name] = tmp.iloc[:,1:].values","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:45.595511Z","iopub.execute_input":"2024-03-20T16:58:45.596413Z","iopub.status.idle":"2024-03-20T16:58:45.848973Z","shell.execute_reply.started":"2024-03-20T16:58:45.596381Z","shell.execute_reply":"2024-03-20T16:58:45.847443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_specs[853520].shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:45.85053Z","iopub.execute_input":"2024-03-20T16:58:45.850888Z","iopub.status.idle":"2024-03-20T16:58:45.857275Z","shell.execute_reply.started":"2024-03-20T16:58:45.850857Z","shell.execute_reply":"2024-03-20T16:58:45.855793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_sub_eeg_sp_data(train_row):\n    \"\"\"Gets EEG and Spectogram data from a specific row in the dataset\"\"\"\n    \n    eeg_id = train_row.eeg_id\n    sp_id = train_row.spectrogram_id\n    \n    eeg_parquet = pd.read_parquet(f'{EEG_SUB_PATH_TEMPL}{eeg_id}.parquet')\n    sp = pd.read_parquet(f'{SP_SUB_PATH_TEMPL}{sp_id}.parquet')\n    \n    rows = len(eeg_parquet)\n    eeg_offset = (rows-10_000)//2\n    \n    \n    # get middle 50 seconds of eeg data\n    #eeg_offset = int(train_row.eeg_label_offset_seconds + 20) #only 10 central seconds from 50 secs were labeled, which should be seconds 20-30 in the sample\n    eeg_data = eeg_parquet.iloc[eeg_offset:eeg_offset + 10_000]\n    \n    \n    # sp_offset = int(train_row.spectrogram_label_offset_seconds )\n    \n    # get spectrogram data\n    # sp = sp_parquet.loc[(sp_parquet.time>=sp_offset)&(sp_parquet.time<sp_offset+SP_WIN)]\n    sp = sp.loc[:, sp.columns != 'time']\n    sp = {\n        \"LL\": sp.filter(regex='^LL', axis=1),\n        \"RL\": sp.filter(regex='^RL', axis=1),\n        \"RP\": sp.filter(regex='^RP', axis=1),\n        \"LP\": sp.filter(regex='^LP', axis=1)}\n    \n    # calculate eeg data\n    # print(eeg_data.keys()) # Has keys Index(['Fp1', 'F3', 'C3', 'P3', 'F7', 'T3', 'T5', 'O1', 'Fz', 'Cz', 'Pz',\n                            # 'Fp2', 'F4', 'C4', 'P4', 'F8', 'T4', 'T6', 'O2', 'EKG']\n    # assert 0 == 1\n    \n    CHAINS = {\n    'LL' : [(\"Fp1\",\"F7\"),(\"F7\",\"T3\"),(\"T3\",\"T5\"),(\"T5\",\"O1\")],\n    'RL' : [(\"Fp2\",\"F8\"),(\"F8\",\"T4\"),(\"T4\",\"T6\"),(\"T6\",\"O2\")],\n    'LP' : [(\"Fp1\",\"F3\"),(\"F3\",\"C3\"),(\"C3\",\"P3\"),(\"P3\",\"O1\")],\n    'RP' : [(\"Fp2\",\"F4\"),(\"F4\",\"C4\"),(\"C4\",\"P4\"),(\"P4\",\"O2\")],\n    'other' : [(\"Fz\",\"Cz\"), (\"Cz\", \"Pz\"), (\"EKG\")]\n}\n    \n    eeg = pd.DataFrame({})\n    for chain in CHAINS.keys():\n        for s_i, signals in enumerate(CHAINS[chain]):\n            if len(signals) == 2:\n                diff=eeg_data[signals[0]]-eeg_data[signals[1]] # Subtracts relevant fields as in the image above\n                diff.ffill(inplace = True) # forward fills in the casse of nan values\n                eeg[f\"{chain}: {signals[0]} - {signals[1]}\"] = diff\n            \n            elif len(signals) == 1:\n                sig=eeg_data[signals[0]]\n                sig.ffill(inplace = True) \n                eeg[f\"{chain}: {signals[0]}\"] = sig\n                \n                \n    \n    return eeg, sp","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:45.877375Z","iopub.execute_input":"2024-03-20T16:58:45.877786Z","iopub.status.idle":"2024-03-20T16:58:45.895872Z","shell.execute_reply.started":"2024-03-20T16:58:45.877752Z","shell.execute_reply":"2024-03-20T16:58:45.894532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eeg_sub, sp_sub = get_sub_eeg_sp_data(test.iloc[0])\n\nprint(eeg_sub.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:45.897584Z","iopub.execute_input":"2024-03-20T16:58:45.898209Z","iopub.status.idle":"2024-03-20T16:58:46.026531Z","shell.execute_reply.started":"2024-03-20T16:58:45.898177Z","shell.execute_reply":"2024-03-20T16:58:46.025024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame({'eeg_id':test.eeg_id.values})\nsub","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:46.028457Z","iopub.execute_input":"2024-03-20T16:58:46.029195Z","iopub.status.idle":"2024-03-20T16:58:46.044252Z","shell.execute_reply.started":"2024-03-20T16:58:46.029151Z","shell.execute_reply":"2024-03-20T16:58:46.042346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eeg_sub = np.expand_dims(eeg_sub, axis=0)\n\nprint(eeg_sub.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:46.046261Z","iopub.execute_input":"2024-03-20T16:58:46.047129Z","iopub.status.idle":"2024-03-20T16:58:46.05484Z","shell.execute_reply.started":"2024-03-20T16:58:46.047086Z","shell.execute_reply":"2024-03-20T16:58:46.053791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prep_eeg_sub = preprocess(eeg_sub)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:46.056279Z","iopub.execute_input":"2024-03-20T16:58:46.056899Z","iopub.status.idle":"2024-03-20T16:58:46.142233Z","shell.execute_reply.started":"2024-03-20T16:58:46.056867Z","shell.execute_reply":"2024-03-20T16:58:46.140911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(prep_eeg_sub.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:46.14378Z","iopub.execute_input":"2024-03-20T16:58:46.14414Z","iopub.status.idle":"2024-03-20T16:58:46.149373Z","shell.execute_reply.started":"2024-03-20T16:58:46.144111Z","shell.execute_reply":"2024-03-20T16:58:46.148154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\nsub_pred = model(torch.from_numpy(prep_eeg_sub).float()) # this gives the log of the probs\n\nsub_pred = np.exp(sub_pred.detach().numpy())\n\nprint(\"This is the sub pred sum:\",sub_pred.sum())\nprint(sub_pred)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:46.150626Z","iopub.execute_input":"2024-03-20T16:58:46.151744Z","iopub.status.idle":"2024-03-20T16:58:46.175263Z","shell.execute_reply.started":"2024-03-20T16:58:46.151707Z","shell.execute_reply":"2024-03-20T16:58:46.174144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CREATE SUBMISSION.CSV\nfrom IPython.display import display\n\nTARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\nsub[TARGETS] = sub_pred\nsub.to_csv('submission.csv',index=False)\nprint('Submission shape',sub.shape)\ndisplay( sub.head() )\n\n# SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\nprint('Sub row 0 sums to:',sub.iloc[0,-6:].sum())","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:46.180841Z","iopub.execute_input":"2024-03-20T16:58:46.181667Z","iopub.status.idle":"2024-03-20T16:58:46.208904Z","shell.execute_reply.started":"2024-03-20T16:58:46.181628Z","shell.execute_reply":"2024-03-20T16:58:46.207371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}